{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 386,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from csv import reader\n",
    "from numpy import linalg as la\n",
    "from sys import exit\n",
    "from haversine import haversine\n",
    "import math\n",
    "from operator import itemgetter\n",
    "from numpy import dot\n",
    "from numpy.linalg import norm\n",
    "#시각화 도구\n",
    "import folium\n",
    "from folium.features import DivIcon\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 387,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 전역 변수 설정\n",
    "FILE_SAVE_DIR = './Data_set_0826/' #있다면 추가 해주기 (상대경로)\n",
    "#Call CSV file\n",
    "def load_GPS_set_to_array(UID): # Data load\n",
    "    try:\n",
    "        data_set = pd.read_csv(FILE_SAVE_DIR + UID +\"_gps\"+\".csv\", sep=\",\", dtype='unicode')\n",
    "        data_set['TIME STAMP'] = pd.to_datetime(data_set['loggingTime'])\n",
    "        data_set['TIME STAMP'] = pd.to_datetime(data_set['TIME STAMP']).map(pd.Timestamp.timestamp) # to unix time \n",
    "        re_data_set = data_set[[\"TIME STAMP\",\"uid\",\"latitude\",\"longitude\",\"provider\",\"speed\"]]\n",
    "        return re_data_set\n",
    "    except FileNotFoundError as e:\n",
    "        pass\n",
    "    \n",
    "def extract_raw_data(UID):\n",
    "    Dataframe = load_GPS_set_to_array(UID)\n",
    "    marker_list = []\n",
    "    for count in range(len(Dataframe.index)):\n",
    "        marker_point_lati = float(Dataframe.loc[count,'latitude'])\n",
    "        marker_point_long = float(Dataframe.loc[count,'longitude'])\n",
    "        marker_point_speed = float(Dataframe.loc[count,'speed'])\n",
    "        marker_point_time = Dataframe.loc[count,'TIME STAMP']\n",
    "        marker_point = [marker_point_time, marker_point_speed, marker_point_lati, marker_point_long]\n",
    "        marker_list.append(marker_point)\n",
    "    return marker_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 388,
   "metadata": {},
   "outputs": [],
   "source": [
    "joongho_raw = extract_raw_data('9E7F4CB4F4A6A6D4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 389,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_state(accuracy):\n",
    "    variance = accuracy * accuracy\n",
    "    return variance\n",
    "\n",
    "def export_new_point(result_map, speed, longitude, latitude, timestamp):\n",
    "    result_map.append([timestamp, speed, latitude, longitude])\n",
    "\n",
    "def kalman_filter(variance, new_speed, latitude, new_latitude, longitude, new_longitude, timestamp, new_timestamp, new_accuracy):\n",
    "\n",
    "    duration = new_timestamp - timestamp\n",
    "    if (duration > 0) :\n",
    "        # time has moved on, so the uncertainty in the current position increases\n",
    "        variance += duration * new_speed * new_speed / 1000\n",
    "\n",
    "    # Kalman gain matrix 'k' = Covariance * Inverse(Covariance + MeasurementVariance)\n",
    "    # because 'k' is dimensionless,\n",
    "    # it doesn't matter that variance has different units to latitude and longitude\n",
    "    k = variance / (variance + new_accuracy * new_accuracy)\n",
    "    # apply 'k'\n",
    "    latitude += k * (new_latitude - latitude)\n",
    "    longitude += k * (new_longitude - longitude)\n",
    "    # new Covariance matrix is (IdentityMatrix - k) * Covariance\n",
    "    variance = (1 - k) * variance\n",
    "\n",
    "    return new_speed, longitude, latitude, duration\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 390,
   "metadata": {},
   "outputs": [],
   "source": [
    "# raw_list = [timestamp(unix), speed, lati, long]\n",
    "FILTER_CONSTANT = 300\n",
    "def precess(raw_list):\n",
    "    variance = -1\n",
    "    Result_map = []\n",
    "    for idx in range(len(raw_list)):\n",
    "        if (variance < 0) :\n",
    "            variance = set_state(FILTER_CONSTANT)\n",
    "        else :\n",
    "            new_speed, longitude, latitude, duration = kalman_filter(variance, raw_list[idx][1], raw_list[idx-1][2], raw_list[idx][2], \n",
    "                                                                     raw_list[idx-1][3], raw_list[idx][3], raw_list[idx-1][0],raw_list[idx][0],FILTER_CONSTANT)\n",
    "                # Export new point\n",
    "            export_new_point(Result_map, new_speed, longitude, latitude, duration)\n",
    "    return Result_map\n",
    "filter_list = precess(joongho_raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 391,
   "metadata": {},
   "outputs": [],
   "source": [
    "kalman_map = folium.Map(location = [37.5505938572,127.074236903], zoom_start =100) # 세종대학교 중심 조사\n",
    "\n",
    "def draw_Polyline_map(map, marker_list, draw_color):\n",
    "    replace_list = []\n",
    "    for marker_point in marker_list:\n",
    "        replace_list.append(marker_point[2:4])\n",
    "    folium.PolyLine(locations=replace_list,tooltip='Polyline',color=draw_color).add_to(map)\n",
    "    \n",
    "def draw_circle_map(map, marker_list,draw_radius,draw_color):\n",
    "    for marker_point in marker_list:\n",
    "        folium.CircleMarker(location=marker_point[2:4], radius=draw_radius, color= draw_color).add_to(map)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 392,
   "metadata": {},
   "outputs": [],
   "source": [
    "#contact result\n",
    "kyounghwan = '3963650B38CAF112'\n",
    "hyeryeong = '4CCF4C0B0F953026'\n",
    "pyeongju = '8A57AE95DD4629A7'\n",
    "joongho = '9E7F4CB4F4A6A6D4'\n",
    "yujin = 'F9888CC2D3053565'\n",
    "\n",
    "kyounghwan_raw = extract_raw_data('3963650B38CAF112')[0:31]\n",
    "hyeryeong_raw = extract_raw_data('4CCF4C0B0F953026')[0:31]\n",
    "pyeongju_raw = extract_raw_data('8A57AE95DD4629A7')[0:31]\n",
    "joongho_raw = extract_raw_data('9E7F4CB4F4A6A6D4')[0:31]\n",
    "yujin_raw = extract_raw_data('F9888CC2D3053565')[0:31]\n",
    "\n",
    "kyounghwan_filter = precess(kyounghwan_raw)[0:31]\n",
    "hyeryeong_filter = precess(hyeryeong_raw)[0:31]\n",
    "pyeongju_filter = precess(pyeongju_raw)[0:31]\n",
    "joongho_filter = precess(joongho_raw)[0:31]\n",
    "yujin_filter = precess(yujin_raw)[0:31]\n",
    "\n",
    "draw_Polyline_map(kalman_map,hyeryeong_filter,\"blue\")\n",
    "draw_circle_map(kalman_map,hyeryeong_filter,3,\"blue\")\n",
    "draw_Polyline_map(kalman_map,hyeryeong_raw,\"red\")\n",
    "draw_circle_map(kalman_map,hyeryeong_raw,3,\"red\")\n",
    "# kalman_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 393,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Local\\Temp/ipykernel_7120/3779354326.py:29: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cosine_sim = dot([patient_speed_x,patient_speed_y], [tester_speed_x,tester_speed_y]) / (norm([patient_speed_x,patient_speed_y]) * norm([tester_speed_x,tester_speed_y]))\n"
     ]
    }
   ],
   "source": [
    "member_list = ['3963650B38CAF112','4CCF4C0B0F953026','8A57AE95DD4629A7','9E7F4CB4F4A6A6D4','F9888CC2D3053565']\n",
    "DISTANCE_TH = 30\n",
    "COSINESIM_TH = 0.7\n",
    "RESULT_LIST = []\n",
    "\n",
    "for patient_id in member_list:\n",
    "    patient_raw = extract_raw_data(patient_id)\n",
    "    for tester_id in member_list:\n",
    "        if tester_id != patient_id:\n",
    "            result_map = {}\n",
    "            result_map[\"patient\"] = patient_id\n",
    "            result_map[\"tester\"] = tester_id\n",
    "            tester_raw = extract_raw_data(tester_id)\n",
    "            \n",
    "            patient_filter = precess(patient_raw)\n",
    "            tester_filter = precess(tester_raw)\n",
    "            \n",
    "            predict_list = []\n",
    "            for idx in range(len(patient_filter)):\n",
    "                try:\n",
    "                    distance = haversine(patient_filter[idx][2:4],tester_filter[idx][2:4], unit = 'm')\n",
    "                    # print(\"patient : \" + patient_id + \"/ tester : \" + tester_id + \" >>>> distance : \" + str(distance))\n",
    "                    if distance <= DISTANCE_TH:\n",
    "                        # print(\"patient : \" + patient_id + \"/ tester : \" + tester_id + \" >>>> distance : \" + str(distance))\n",
    "                        patient_speed_x = patient_filter[idx + 1][2] - patient_filter[idx][2]\n",
    "                        patient_speed_y = patient_filter[idx + 1][3] - patient_filter[idx][3]\n",
    "                        tester_speed_x = tester_filter[idx + 1][2] - tester_filter[idx][2]\n",
    "                        tester_speed_y = tester_filter[idx + 1][3] - tester_filter[idx][3]\n",
    "                        cosine_sim = dot([patient_speed_x,patient_speed_y], [tester_speed_x,tester_speed_y]) / (norm([patient_speed_x,patient_speed_y]) * norm([tester_speed_x,tester_speed_y]))\n",
    "                        if cosine_sim >= COSINESIM_TH:\n",
    "                        # if cosine_sim >= COSINESIM_TH or cosine_sim <= -COSINESIM_TH:\n",
    "                            # print(\"<<<<<< cosine : \" + str(cosine_sim))\n",
    "                            predict_list.append(1)\n",
    "                        else:\n",
    "                            predict_list.append(0)\n",
    "                    else:\n",
    "                        predict_list.append(0)\n",
    "                except IndexError:\n",
    "                    break\n",
    "            result_map[\"predict\"] = predict_list\n",
    "            RESULT_LIST.append(result_map)\n",
    "# print(RESULT_LIST)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 394,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.99      0.87       907\n",
      "           1       0.97      0.39      0.56       431\n",
      "\n",
      "    accuracy                           0.80      1338\n",
      "   macro avg       0.87      0.69      0.72      1338\n",
      "weighted avg       0.84      0.80      0.77      1338\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'              precision    recall  f1-score   support\\n\\n           0       0.78      0.99      0.87       907\\n           1       0.97      0.39      0.56       431\\n\\n    accuracy                           0.80      1338\\n   macro avg       0.87      0.69      0.72      1338\\nweighted avg       0.84      0.80      0.77      1338\\n'"
      ]
     },
     "execution_count": 394,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_groundtruth(patient_id, tester_id):\n",
    "    try:\n",
    "        data_set = pd.read_csv(FILE_SAVE_DIR + patient_id +\"_gps\"+\".csv\", sep=\",\", dtype='unicode')\n",
    "        data_set['TIME STAMP'] = pd.to_datetime(data_set['loggingTime'])\n",
    "        data_set['TIME STAMP'] = pd.to_datetime(data_set['TIME STAMP']).map(pd.Timestamp.timestamp) # to unix time \n",
    "        re_data_set = data_set[[\"c_\"+tester_id]]\n",
    "        return re_data_set\n",
    "    except FileNotFoundError as e:\n",
    "        pass\n",
    "\n",
    "def get_result():\n",
    "    RESULT_MAP = {}\n",
    "    for result in RESULT_LIST:\n",
    "        groundtruth = get_groundtruth(result[\"patient\"], result[\"tester\"]).values.tolist()\n",
    "        gt = []\n",
    "        for e in groundtruth:\n",
    "            gt.append(int(e[0]))\n",
    "        predict_res = classification_report(gt[0:len(result[\"predict\"])] ,result[\"predict\"])\n",
    "        print(\"patient : \"+result[\"patient\"])\n",
    "        print(\"tester : \"+result[\"tester\"])\n",
    "        print(\"get : \"+str(gt[0:len(result[\"predict\"])]))\n",
    "        print(\"pred : \"+str(result[\"predict\"]))\n",
    "        print(predict_res)\n",
    "        RESULT_MAP[\"patient\"] = result[\"patient\"]\n",
    "        RESULT_MAP[\"tester\"] = result[\"tester\"]\n",
    "        RESULT_MAP[\"result\"] = predict_res\n",
    "    return RESULT_MAP\n",
    "\n",
    "\n",
    "def total_result():\n",
    "    total_gt = []\n",
    "    total_pre = []\n",
    "    for result in RESULT_LIST:\n",
    "        groundtruth = get_groundtruth(result[\"patient\"], result[\"tester\"]).values.tolist()\n",
    "        gt = []\n",
    "        for e in groundtruth:\n",
    "            gt.append(int(e[0]))\n",
    "        total_gt.append(gt[0:len(result[\"predict\"])])\n",
    "        total_pre.append(result[\"predict\"])\n",
    "    total_gt = sum(total_gt, [])\n",
    "    total_pre = sum(total_pre, [])\n",
    "    predict_res = classification_report(total_gt ,total_pre)\n",
    "    print(predict_res)\n",
    "    return predict_res\n",
    "# get_result()\n",
    "total_result()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "wifi",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c91022f29e5629089bc7e67134e9b7edd658fd95461bf2edd86049ce150f6801"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
