{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from csv import reader\n",
    "from numpy import linalg as la\n",
    "from sys import exit\n",
    "from haversine import haversine\n",
    "import math\n",
    "from operator import itemgetter\n",
    "\n",
    "#시각화 도구\n",
    "import folium\n",
    "from folium.features import DivIcon\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 전역 변수 설정\n",
    "FILE_SAVE_DIR = './Data_set_0402/' #있다면 추가 해주기 (상대경로)\n",
    "line_color_list = ['red', 'blue', 'green', 'purple', 'orange', 'darkred',\n",
    "                    'lightred', 'beige', 'darkblue', 'darkgreen', 'cadetblue', 'darkpurple', 'white',\n",
    "                    'pink', 'lightblue', 'lightgreen', 'gray', 'black', 'lightgray'] \n",
    "# Global Variable Setting\n",
    "\n",
    "# Nicname = '5CAC8432AE4EC54B'\n",
    "# Huzzi = '44754E5A077F32B4'\n",
    "# oizi = '2DDB3706DE4F7B45'\n",
    "kyounghwan = '3963650B38CAF112'\n",
    "ryeong = '72294652E731441B'\n",
    "soo = '29D97405E68FA578'\n",
    "\n",
    "PATIENT_UID = kyounghwan # 감염자 UID\n",
    "TARGET_UID =  ryeong # 조사 대상자 UID\n",
    "\n",
    "# Map Setting\n",
    "Raw_map = folium.Map(location = [37.5505938572,127.074236903], zoom_start =100) # 세종대학교 중심 조사\n",
    "Filter_map = folium.Map(location = [37.5505938572,127.074236903], zoom_start =100) # 세종대학교 중심 조사\n",
    "mass_map = folium.Map(location = [37.5505938572,127.074236903], zoom_start =100) # 세종대학교 중심 조사\n",
    "compare_map = folium.Map(location = [37.5505938572,127.074236903], zoom_start =100) # 세종대학교 중심 조사\n",
    "\n",
    "#Call CSV file\n",
    "def load_GPS_set(UID): # Data load\n",
    "    try:\n",
    "        data_set = pd.read_csv(FILE_SAVE_DIR + UID +\"_gps\"+\".csv\", sep=\",\", dtype='unicode')\n",
    "        data_set['TIME STAMP'] = pd.to_datetime(data_set['LOG TIME']).dt.strftime('%Y-%m-%d %H:%M:%s')\n",
    "        # data_set['TIME'] = data_set['TIME STAMP'].dt.strftime('%Y-%m-%d %H:%M') # 초단위 자르기\n",
    "        # data_set['STAMP_TIME'] = pd.to_datetime(data_set['TIME']) # stamp_time datetime 형식으로 변경\n",
    "        re_data_set = data_set[[\"TIME STAMP\",\"UID\",\"altitude\",\"latitude\",\"longitude\",\"provider\"]]\n",
    "        return re_data_set\n",
    "    \n",
    "    except FileNotFoundError as e:\n",
    "        pass\n",
    "def load_Sateillate_set(UID): # Data load\n",
    "    try:\n",
    "        data_set = pd.read_csv(FILE_SAVE_DIR + UID +\"_sate\"+\".csv\", sep=\",\", dtype='unicode')\n",
    "        \n",
    "        data_set['TIME STAMP'] = pd.to_datetime(data_set['LOG TIME']).dt.strftime('%Y-%m-%d %H:%M:%s')\n",
    "        # data_set['TIME'] = data_set['TIME STAMP'].dt.strftime('%Y-%m-%d %H:%M') # 초단위 자르기\n",
    "        # data_set['STAMP_TIME'] = pd.to_datetime(data_set['TIME']) # stamp_time datetime 형식으로 변경\n",
    "        re_data_set = data_set[[\"TIME STAMP\",\"UID\",\"SNR AVERAGE\",\"SATELLITE COUNT\"]]\n",
    "        return re_data_set\n",
    "    \n",
    "    except FileNotFoundError as e:\n",
    "        pass\n",
    "\n",
    "def merge_gps_sati_set(UID): # for weight_filter\n",
    "    gps_df = load_GPS_set(UID)\n",
    "    sat_df = load_Sateillate_set(UID)\n",
    "    merge_df = pd.merge(gps_df,sat_df, how='left', on = ['TIME STAMP','UID'])\n",
    "    return merge_df\n",
    "\n",
    "################### RAW DATA FUNC ######################\n",
    "def extract_raw_data(UID,start,end):\n",
    "    Dataframe = merge_gps_sati_set(UID)\n",
    "    marker_list = []\n",
    "    for count in range(start,end):\n",
    "        marker_point_lati = float(Dataframe.loc[count,'latitude'])\n",
    "        marker_point_long = float(Dataframe.loc[count,'longitude'])\n",
    "        marker_point_time = Dataframe.loc[count,'TIME STAMP']\n",
    "        marker_point = [marker_point_time, marker_point_lati, marker_point_long]\n",
    "        marker_list.append(marker_point)\n",
    "    is_idx = Dataframe.index <= end\n",
    "    Dataframe = Dataframe[is_idx]\n",
    "    return marker_list, Dataframe\n",
    "    \n",
    "################### ABOUT MAP DROWING FUNC #####################\n",
    "def draw_Polyline_map(map, marker_list, draw_color):\n",
    "    replace_list = []\n",
    "    for marker_point in marker_list:\n",
    "        replace_list.append(marker_point[1:3])\n",
    "    folium.PolyLine(locations=replace_list,tooltip='Polyline',color=draw_color).add_to(map)\n",
    "\n",
    "def draw_index_map(map, marker_list):\n",
    "    count = len(marker_list)\n",
    "    for marker_point in marker_list:\n",
    "        folium.Marker(marker_point[1:3], icon=DivIcon(icon_size=(10,3),icon_anchor=(7,20),\n",
    "        html='<div style=\"font-size: 10pt; color : black\">'+str(count)+'</div>',\n",
    "        )).add_to(map)\n",
    "        count = count - 1\n",
    "\n",
    "def draw_circle_map(map, marker_list,draw_radius,draw_color):\n",
    "    for marker_point in marker_list:\n",
    "        folium.CircleMarker(location=marker_point[1:3], radius=draw_radius, color= draw_color).add_to(map)\n",
    "        \n",
    "def draw_arrow_map(map, start_list, end_list, line_color, dot_color):\n",
    "    for start_point in start_list:\n",
    "        for end_point in end_list:\n",
    "            if(start_point[0]==end_point[0]):\n",
    "                try:\n",
    "                    rot_x = end_point[1] - start_point[1]\n",
    "                    rot_y = end_point[2] - start_point[2]\n",
    "                    rot = math.acos(haversine([start_point[1],0],[end_point[1],0])/haversine(start_point[1:3],end_point[1:3]))\n",
    "                    folium.CircleMarker(location=start_point[1:3], radius=3, color= dot_color).add_to(map)\n",
    "                    folium.CircleMarker(location=end_point[1:3], radius=3, color= dot_color).add_to(map)\n",
    "                    folium.PolyLine(locations=[start_point[1:3],end_point[1:3]],tooltip='Polyline',color=line_color).add_to(map)\n",
    "                    folium.RegularPolygonMarker(end_point[1:3], fill_color='blue', number_of_sides=3, radius=5, rotation=rot).add_to(map)\n",
    "                except IndexError :\n",
    "                    break\n",
    "                except ZeroDivisionError:\n",
    "                    break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "FILTER_CONSTANT = 5\n",
    "\n",
    "soo_raw, soo_df = extract_raw_data(soo,1,517)\n",
    "soo_avg_point = []\n",
    "\n",
    "for idx in range(len(soo_raw)):\n",
    "    x = soo_raw[idx][1]\n",
    "    y = soo_raw[idx][2]\n",
    "    avg_x = 0\n",
    "    avg_y = 0\n",
    "    for avgIdx in range(idx,idx + FILTER_CONSTANT):\n",
    "        try:\n",
    "            avg_x += soo_raw[avgIdx][1]\n",
    "            avg_y += soo_raw[avgIdx][2]\n",
    "        except IndexError:\n",
    "            break\n",
    "    avg_x = avg_x / FILTER_CONSTANT\n",
    "    avg_y = avg_y / FILTER_CONSTANT\n",
    "    point = [soo_raw[idx][0], avg_x, avg_y]\n",
    "    soo_avg_point.append(point)\n",
    "    \n",
    "ryeong_raw, ryeong_df = extract_raw_data(ryeong,1,314)\n",
    "ryeong_avg_point = []\n",
    "\n",
    "for idx in range(len(ryeong_raw)):\n",
    "    x = ryeong_raw[idx][1]\n",
    "    y = ryeong_raw[idx][2]\n",
    "    avg_x = 0\n",
    "    avg_y = 0\n",
    "    for avgIdx in range(idx,idx + FILTER_CONSTANT):\n",
    "        try:\n",
    "            avg_x += ryeong_raw[avgIdx][1]\n",
    "            avg_y += ryeong_raw[avgIdx][2]\n",
    "        except IndexError:\n",
    "            break\n",
    "    avg_x = avg_x / FILTER_CONSTANT\n",
    "    avg_y = avg_y / FILTER_CONSTANT\n",
    "    point = [ryeong_raw[idx][0], avg_x, avg_y]\n",
    "    ryeong_avg_point.append(point)\n",
    "    \n",
    "kyoung_raw, kyoung_df = extract_raw_data(kyounghwan,1,516)\n",
    "kyoung_avg_point = []\n",
    "\n",
    "for idx in range(len(kyoung_raw)):\n",
    "    x = kyoung_raw[idx][1]\n",
    "    y = kyoung_raw[idx][2]\n",
    "    avg_x = 0\n",
    "    avg_y = 0\n",
    "    for avgIdx in range(idx,idx + FILTER_CONSTANT):\n",
    "        try:\n",
    "            avg_x += kyoung_raw[avgIdx][1]\n",
    "            avg_y += kyoung_raw[avgIdx][2]\n",
    "        except IndexError:\n",
    "            break\n",
    "    avg_x = avg_x / FILTER_CONSTANT\n",
    "    avg_y = avg_y / FILTER_CONSTANT\n",
    "    point = [kyoung_raw[idx][0], avg_x, avg_y]\n",
    "    kyoung_avg_point.append(point)\n",
    "\n",
    "draw_arrow_map(Filter_map,soo_raw,soo_avg_point,\"red\", \"blue\")\n",
    "draw_arrow_map(Filter_map,ryeong_raw,ryeong_avg_point,\"red\", \"blue\")\n",
    "draw_arrow_map(Filter_map,kyoung_raw,kyoung_avg_point,\"red\", \"blue\")\n",
    "\n",
    "# Filter_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "soo_speed_vec = []\n",
    "ryeong_speed_vec = []\n",
    "kyoung_speed_vec = []\n",
    "\n",
    "for idx in range(len(soo_raw)):\n",
    "    try:\n",
    "        speed_x = soo_raw[idx][1] - soo_avg_point[idx][1]\n",
    "        speed_y = soo_raw[idx][2] - soo_avg_point[idx][2]\n",
    "        speed = [soo_raw[idx][0], speed_x, speed_y]\n",
    "        soo_speed_vec.append(speed)\n",
    "    except IndexError:\n",
    "        break\n",
    "\n",
    "for idx in range(len(ryeong_raw)):\n",
    "    try:\n",
    "        speed_x = ryeong_raw[idx][1] - ryeong_avg_point[idx][1]\n",
    "        speed_y = ryeong_raw[idx][2] - ryeong_avg_point[idx][2]\n",
    "        speed = [ryeong_raw[idx][0], speed_x, speed_y]\n",
    "        ryeong_speed_vec.append(speed)\n",
    "    except IndexError:\n",
    "        break\n",
    "    \n",
    "for idx in range(len(kyoung_raw)):\n",
    "    try:\n",
    "        speed_x = kyoung_raw[idx][1] - kyoung_avg_point[idx][1]\n",
    "        speed_y = kyoung_raw[idx][2] - kyoung_avg_point[idx][2]\n",
    "        speed = [kyoung_raw[idx][0], speed_x, speed_y]\n",
    "        kyoung_speed_vec.append(speed)\n",
    "    except IndexError:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Local\\Temp/ipykernel_19280/4633410.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  tester[\"TIME STAMP\"] = pd.to_datetime(tester[\"TIME STAMP\"]).dt.strftime('%Y-%m-%d %H:%M')\n",
      "C:\\Users\\User\\AppData\\Local\\Temp/ipykernel_19280/4633410.py:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  patient[\"TIME STAMP\"] = pd.to_datetime(patient[\"TIME STAMP\"]).dt.strftime('%Y-%m-%d %H:%M')\n",
      "c:\\Users\\User\\anaconda3\\envs\\wifi\\lib\\site-packages\\numpy\\core\\fromnumeric.py:3372: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "c:\\Users\\User\\anaconda3\\envs\\wifi\\lib\\site-packages\\numpy\\core\\_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "C:\\Users\\User\\AppData\\Local\\Temp/ipykernel_19280/4633410.py:51: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cosine_similar = dot(speed_point_patient[1:3], speed_point_tester[1:3]) / (norm(speed_point_patient[1:3]) * norm(speed_point_tester[1:3]))\n"
     ]
    }
   ],
   "source": [
    "#contact 비교\n",
    "from numpy import dot\n",
    "from numpy.linalg import norm\n",
    "def extractTime(DataFrame):\n",
    "    timeStamp = np.unique(DataFrame[\"TIME STAMP\"])\n",
    "    # convertTimeStamp = timeStamp[~pd.isnull(timeStamp)]\n",
    "    # resTimeStamp = np.unique(convertTimeStamp)\n",
    "    return timeStamp\n",
    "\n",
    "patient = kyoung_df\n",
    "tester = soo_df\n",
    "\n",
    "tester = tester[[\"TIME STAMP\", \"latitude\", \"longitude\"]]\n",
    "tester[\"TIME STAMP\"] = pd.to_datetime(tester[\"TIME STAMP\"]).dt.strftime('%Y-%m-%d %H:%M')\n",
    "\n",
    "patient = patient[[\"TIME STAMP\", \"latitude\", \"longitude\"]]\n",
    "patient[\"TIME STAMP\"] = pd.to_datetime(patient[\"TIME STAMP\"]).dt.strftime('%Y-%m-%d %H:%M')\n",
    "\n",
    "time_stamp = extractTime(patient)\n",
    "\n",
    "contact_df = pd.DataFrame(columns=[\"TIME\", \"Distance\", \"Cosine\", \"Threshold\", \"Contact\"])\n",
    "contact_df[\"TIME\"] = time_stamp\n",
    "contact_df.set_index(\"TIME\", inplace = True)\n",
    "for time in time_stamp:\n",
    "    is_patient_time = patient[\"TIME STAMP\"] == time\n",
    "    is_tester_time = tester[\"TIME STAMP\"] == time\n",
    "    is_time_patient_df = patient[is_patient_time]\n",
    "    is_time_tester_df = tester[is_tester_time]\n",
    "    is_time_patient_df = is_time_patient_df.reset_index(drop=True)\n",
    "    is_time_tester_df = is_time_tester_df.reset_index(drop=True)\n",
    "\n",
    "    distance_list = [100000]\n",
    "    for idx_patient in range(0, len(is_time_patient_df.index)):\n",
    "        for idx_tester in range(0, len(is_time_tester_df.index)):\n",
    "            try:\n",
    "                patient_point = [float(is_time_patient_df.loc[idx_patient,\"latitude\"]),float(is_time_patient_df.loc[idx_patient,\"longitude\"])]\n",
    "                tester_point = [float(is_time_tester_df.loc[idx_tester,\"latitude\"]),float(is_time_tester_df.loc[idx_tester,\"longitude\"])]\n",
    "                distance = haversine(patient_point,tester_point, unit = 'm')\n",
    "                distance_list.append(distance)\n",
    "            except IndexError:\n",
    "                break\n",
    "            except KeyError:\n",
    "                break\n",
    "    contact_df.loc[time,\"Distance\"] = min(distance_list)\n",
    "    if min(distance_list) <= 5:\n",
    "        cosine_similar_list = []\n",
    "        for speed_point_patient in kyoung_speed_vec:\n",
    "            if time in speed_point_patient[0]:\n",
    "                for speed_point_tester in ryeong_speed_vec:\n",
    "                    if time in speed_point_tester[0] :\n",
    "                        cosine_similar = dot(speed_point_patient[1:3], speed_point_tester[1:3]) / (norm(speed_point_patient[1:3]) * norm(speed_point_tester[1:3]))\n",
    "                        cosine_similar_list.append(cosine_similar)\n",
    "        contact_df.loc[time,\"Cosine\"] = np.mean(cosine_similar_list)\n",
    "    else : \n",
    "        contact_df.loc[time,\"Cosine\"] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26 44 0.5909090909090909\n"
     ]
    }
   ],
   "source": [
    "WINDOW_SIZE = 10\n",
    "EXPOSED_CONSTANT = 5\n",
    "THRESHOLD = 0.1\n",
    "exposed_df = pd.DataFrame(columns=[\"TIME\", \"Cosine_avg\", \"Exposed\", \"Threshold\",\"GroundTruth\"])\n",
    "exposed_df[\"TIME\"] = time_stamp\n",
    "exposed_df[\"Threshold\"] = THRESHOLD\n",
    "KH_SR_GroundTruth = [\"FALSE\",\"FALSE\",\"FALSE\",\"FALSE\",\"FALSE\",\"FALSE\",\"FALSE\",\"TRUE\",\"TRUE\",\"TRUE\",\"TRUE\",\"TRUE\",\"TRUE\",\"FALSE\",\"FALSE\",\"FALSE\",\"FALSE\",\"FALSE\",\"FALSE\",\"FALSE\",\"FALSE\",\"FALSE\",\"FALSE\",\"FALSE\",\"FALSE\",\"FALSE\",\"FALSE\",\"FALSE\",\"FALSE\",\"FALSE\",\"FALSE\",\"FALSE\",\"FALSE\",\"FALSE\",\"FALSE\",\"FALSE\",\"TRUE\",\"TRUE\",\"TRUE\",\"TRUE\",\"TRUE\",\"TRUE\",\"TRUE\",\"TRUE\"]\n",
    "exposed_df[\"GroundTruth\"] = KH_SR_GroundTruth\n",
    "\n",
    "cosine_avg_list = []\n",
    "contact_df = contact_df.reset_index(drop=True)\n",
    "for idx in range(0, len(contact_df.index)):\n",
    "    cosine_avg = 0\n",
    "    for window_idx in range(idx, idx+WINDOW_SIZE):\n",
    "        try:\n",
    "            cosine = contact_df.loc[window_idx, \"Cosine\"]\n",
    "            cosine_avg += cosine\n",
    "        except KeyError:\n",
    "            cosine_avg = 0\n",
    "            continue\n",
    "    cosine_avg = cosine_avg / WINDOW_SIZE\n",
    "    cosine_avg_list.append(cosine_avg)\n",
    "exposed_df[\"Cosine_avg\"] = cosine_avg_list\n",
    "for idx in range(len(exposed_df[\"Cosine_avg\"])):\n",
    "    if exposed_df.loc[idx, \"Cosine_avg\"] >= THRESHOLD:\n",
    "        exposed_df.loc[idx, \"Exposed\"] = \"TRUE\"\n",
    "    else :\n",
    "        exposed_df.loc[idx, \"Exposed\"] = \"FALSE\"\n",
    "# exposed_df.to_csv('KH_SR.csv')\n",
    "cnt = 0\n",
    "for idx in range(len(exposed_df.index)):\n",
    "    if exposed_df.loc[idx, \"Exposed\"] == exposed_df.loc[idx, \"GroundTruth\"]:\n",
    "        cnt +=1\n",
    "acc = cnt / len(exposed_df.index)\n",
    "print(cnt, len(exposed_df.index), acc)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.5 ('wifi')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c91022f29e5629089bc7e67134e9b7edd658fd95461bf2edd86049ce150f6801"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
